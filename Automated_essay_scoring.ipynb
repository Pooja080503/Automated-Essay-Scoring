{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ezcVd03ZJ_Xf"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A7XD8gbvKVTs",
        "outputId": "d712f21d-85b3-464c-a4c5-28b3ca02e740"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import nltk\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import sent_tokenize,word_tokenize\n",
        "from gensim.models import Word2Vec\n",
        "from keras.layers import Embedding, LSTM, Dense, Dropout, Lambda, Flatten\n",
        "from keras.models import Sequential, load_model\n",
        "# Instead of importing model_from_config, you should directly load your model using load_model\n",
        "# from keras.models import Sequential, load_model, model_from_config\n",
        "import keras.backend as K\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import cohen_kappa_score"
      ],
      "metadata": {
        "id": "5D4CDhYhLQGG"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/drive/MyDrive/training_set_rel3.tsv\", sep='\\t', encoding='ISO-8859-1');\n",
        "df.dropna(axis=1,inplace=True)\n",
        "df.drop(columns=['domain1_score','rater1_domain1','rater2_domain1'],inplace=True,axis=1)\n",
        "df.head()\n",
        "temp = pd.read_csv(\"/content/drive/MyDrive/Processed_data.csv\")\n",
        "temp.drop(\"Unnamed: 0\",inplace=True,axis=1)"
      ],
      "metadata": {
        "id": "EWpKejF6LSEF"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['domain1_score']=temp['final_score']\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "id": "15sQ1cg1NaYm",
        "outputId": "e9a1639f-0834-4ee2-9afb-3f96572193d0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   essay_id  essay_set                                              essay  \\\n",
              "0         1          1  Dear local newspaper, I think effects computer...   \n",
              "1         2          1  Dear @CAPS1 @CAPS2, I believe that using compu...   \n",
              "2         3          1  Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...   \n",
              "3         4          1  Dear Local Newspaper, @CAPS1 I have found that...   \n",
              "4         5          1  Dear @LOCATION1, I know having computers has a...   \n",
              "\n",
              "   domain1_score  \n",
              "0              6  \n",
              "1              7  \n",
              "2              5  \n",
              "3              8  \n",
              "4              6  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4427c808-9f3c-4b99-809c-ddc88d3fd4be\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>essay_id</th>\n",
              "      <th>essay_set</th>\n",
              "      <th>essay</th>\n",
              "      <th>domain1_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Dear local newspaper, I think effects computer...</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>Dear @CAPS1 @CAPS2, I believe that using compu...</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>Dear Local Newspaper, @CAPS1 I have found that...</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>Dear @LOCATION1, I know having computers has a...</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4427c808-9f3c-4b99-809c-ddc88d3fd4be')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4427c808-9f3c-4b99-809c-ddc88d3fd4be button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4427c808-9f3c-4b99-809c-ddc88d3fd4be');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-2c347f77-3be2-47f4-8e53-553fd020a793\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2c347f77-3be2-47f4-8e53-553fd020a793')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-2c347f77-3be2-47f4-8e53-553fd020a793 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 12976,\n  \"fields\": [\n    {\n      \"column\": \"essay_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6309,\n        \"min\": 1,\n        \"max\": 21633,\n        \"num_unique_values\": 12976,\n        \"samples\": [\n          9908,\n          9872,\n          305\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"essay_set\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 1,\n        \"max\": 8,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          2,\n          6,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"essay\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 12972,\n        \"samples\": [\n          \"The features of the setting affect the cyclist in many ways. He is riding his bike along the road and encounters a dilema.\\u0094\\u0085 @CAPS1 weeds crossed my path and a ridiculously large snake. Blocked the\\u0085 pavement in front of me.\\u0094 He had to stop and into by the snake which showed him down and freaked him out. He had problems with thirst already and had to deal with a snake that \\u0093really did look like a diamondback.\\u0094 @CAPS2, he sees a building up ahead and discovers that it\\u0092s a walrus Grape Juice factory. He thought that is might have some water but realized it was abandoned. Relating to his thirst, before he left he grabbed some pebbles.\\u0094 I\\u0092d read once that sucking on stones helps takes your mind off thirst by allowing what spit you have left to circulate.\\u0094 * @CAPS3 he came across a fishing camp and received instructions on how to go on. This affected him because he @CAPS3 got to a secure place and got proper directions and will learn from his mistake of listening to the older men at the beginning. The features of \",\n          \"The author concludes the story with this paragraph because the cold was brufield or the  author never  wanted to be around while the cold was in sesion. At the  time it was realy cold\",\n          \"Computers, a very much talked about subject. Did you know that @PERCENT1 of homes in @LOCATION1 own at least one computer. And that goes for about @PERCENT2 in @LOCATION2. Some people don't like that this is true, but on the other hand some people do. I have a computer, it can do so much, for example it can help me with writing, I can play games on it and socialize with social networking sites and \\\"I.M.'s\\\", it can even help me order a product form a website like @ORGANIZATION1, @LOCATION3, or @LOCATION4. Like I said, I have a computer and I can use it to help me write. At school in english, I would use my computer to help me with a writing prompt. I also use it to write conclusions for science labs. There are a lot of other kids that do this as well, it really is very helpful. That is only one of the reasons I think computers are beneficial to society. Another reason I think computers are beneficial to society is because you can play games on them, like \\\"world of warcraft\\\", \\\"@CAPS1 @CAPS2 @NUM1\\\", or classics like \\\"@CAPS3 @CAPS4 @CAPS5\\\". There are millions of people that play games on the computer. Also you can socialize with social networking sites, like @CAPS6 and twitter, and also because you can \\\"I.M.\\\" your friends. I.M. stands for @CAPS7 messaging, and it is kind of like email except it is just about instantaneous, and so you and friend can have a conversation over the computer. Also there is video chatting, where it is kind of like a phone except you can see the person you're talking to and it is over the computer, so it is almost like you and the person you are videochatting with are meeting face to face, but your not. A third reason I feel that computers are beneficial to society is because you can order a product over the internet form shop websites. For example, I got my @CAPS8 from @LOCATION3, and also the bulb for a @CAPS9 in my house is wearing out, so my dad is going to buy a @LOCATION1 bulb on @ORGANIZATION1. It is things like this that make life that much easier for the @CAPS10 @PERSON1, because this way these people don't have to drive to the store to buy something, that is, if they can wait a week or two for the product to arrive. These are the kinds of things that make me feel that computers are beneficial to society. I know they might not be the best reasons, but they are quite important to me. Being able to type essays, play games and socialize, and order products form websites is just amazing. These are some of the reasons that I and others love computers. But I have a question for you, why do you like or dislike computers?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"domain1_score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 0,\n        \"max\": 10,\n        \"num_unique_values\": 11,\n        \"samples\": [\n          10,\n          6,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['essay'][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "XEFoRq1bNhJT",
        "outputId": "9b8908ed-5df7-42cb-db45-62a3037efcd5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Dear local newspaper, I think effects computers have on people are great learning skills/affects because they give us time to chat with friends/new people, helps us learn about the globe(astronomy) and keeps us out of troble! Thing about! Dont you think so? How would you feel if your teenager is always on the phone with friends! Do you ever time to chat with your friends or buisness partner about things. Well now - there's a new way to chat the computer, theirs plenty of sites on the internet to do so: @ORGANIZATION1, @ORGANIZATION2, @CAPS1, facebook, myspace ect. Just think now while your setting up meeting with your boss on the computer, your teenager is having fun on the phone not rushing to get off cause you want to use it. How did you learn about other countrys/states outside of yours? Well I have by computer/internet, it's a new way to learn about what going on in our time! You might think your child spends a lot of time on the computer, but ask them so question about the economy, sea floor spreading or even about the @DATE1's you'll be surprise at how much he/she knows. Believe it or not the computer is much interesting then in class all day reading out of books. If your child is home on your computer or at a local library, it's better than being out with friends being fresh, or being perpressured to doing something they know isnt right. You might not know where your child is, @CAPS2 forbidde in a hospital bed because of a drive-by. Rather than your child on the computer learning, chatting or just playing games, safe and sound in your home or community place. Now I hope you have reached a point to understand and agree with me, because computers can have great effects on you or child because it gives us time to chat with friends/new people, helps us learn about the globe and believe or not keeps us out of troble. Thank you for listening.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "temp.head(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "id": "JYF5Vt0UNmoR",
        "outputId": "d9c37d60-33fe-4c6d-dcf9-f6dae636e4f2"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   essay_id  essay_set                                              essay  \\\n",
              "0         1          1  Dear local newspaper, I think effects computer...   \n",
              "\n",
              "   final_score                                        clean_essay  char_count  \\\n",
              "0            6  Dear local newspaper  I think effects computer...        1441   \n",
              "\n",
              "   word_count  sent_count  avg_word_len  spell_err_count  noun_count  \\\n",
              "0         344          16      4.188953               11          76   \n",
              "\n",
              "   adj_count  verb_count  adv_count  \n",
              "0         75          18         24  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c96eec03-2679-4e41-b3c7-77340e5aba45\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>essay_id</th>\n",
              "      <th>essay_set</th>\n",
              "      <th>essay</th>\n",
              "      <th>final_score</th>\n",
              "      <th>clean_essay</th>\n",
              "      <th>char_count</th>\n",
              "      <th>word_count</th>\n",
              "      <th>sent_count</th>\n",
              "      <th>avg_word_len</th>\n",
              "      <th>spell_err_count</th>\n",
              "      <th>noun_count</th>\n",
              "      <th>adj_count</th>\n",
              "      <th>verb_count</th>\n",
              "      <th>adv_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Dear local newspaper, I think effects computer...</td>\n",
              "      <td>6</td>\n",
              "      <td>Dear local newspaper  I think effects computer...</td>\n",
              "      <td>1441</td>\n",
              "      <td>344</td>\n",
              "      <td>16</td>\n",
              "      <td>4.188953</td>\n",
              "      <td>11</td>\n",
              "      <td>76</td>\n",
              "      <td>75</td>\n",
              "      <td>18</td>\n",
              "      <td>24</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c96eec03-2679-4e41-b3c7-77340e5aba45')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c96eec03-2679-4e41-b3c7-77340e5aba45 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c96eec03-2679-4e41-b3c7-77340e5aba45');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "temp",
              "summary": "{\n  \"name\": \"temp\",\n  \"rows\": 12976,\n  \"fields\": [\n    {\n      \"column\": \"essay_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6309,\n        \"min\": 1,\n        \"max\": 21633,\n        \"num_unique_values\": 12976,\n        \"samples\": [\n          9908,\n          9872,\n          305\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"essay_set\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 1,\n        \"max\": 8,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          2,\n          6,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"essay\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 12972,\n        \"samples\": [\n          \"The features of the setting affect the cyclist in many ways. He is riding his bike along the road and encounters a dilema.\\u0094 weeds crossed my path and a ridiculously large snake. Blocked the pavement in front of me.\\u0094 He had to stop and into by the snake which showed him down and freaked him out. He had problems with thirst already and had to deal with a snake that \\u0093really did look like a diamondback.\\u0094 he sees a building up ahead and discovers that it\\u0092s a walrus Grape Juice factory. He thought that is might have some water but realized it was abandoned. Relating to his thirst, before he left he grabbed some pebbles.\\u0094 I\\u0092d read once that sucking on stones helps takes your mind off thirst by allowing what spit you have left to circulate.\\u0094 * he came across a fishing camp and received instructions on how to go on. This affected him because he got to a secure place and got proper directions and will learn from his mistake of listening to the older men at the beginning. The features of\",\n          \"The author concludes the story with this paragraph because the cold was brufield or the author never wanted to be around while the cold was in sesion. At the time it was realy cold\",\n          \"Computers, a very much talked about subject. Did you know that of homes in own at least one computer. And that goes for about in Some people don't like that this is true, but on the other hand some people do. I have a computer, it can do so much, for example it can help me with writing, I can play games on it and socialize with social networking sites and \\\"I.M.'s\\\", it can even help me order a product form a website like or Like I said, I have a computer and I can use it to help me write. At school in english, I would use my computer to help me with a writing prompt. I also use it to write conclusions for science labs. There are a lot of other kids that do this as well, it really is very helpful. That is only one of the reasons I think computers are beneficial to society. Another reason I think computers are beneficial to society is because you can play games on them, like \\\"world of warcraft\\\", \\\"@CAPS1 or classics like \\\"@CAPS3 There are millions of people that play games on the computer. Also you can socialize with social networking sites, like and twitter, and also because you can \\\"I.M.\\\" your friends. I.M. stands for messaging, and it is kind of like email except it is just about instantaneous, and so you and friend can have a conversation over the computer. Also there is video chatting, where it is kind of like a phone except you can see the person you're talking to and it is over the computer, so it is almost like you and the person you are videochatting with are meeting face to face, but your not. A third reason I feel that computers are beneficial to society is because you can order a product over the internet form shop websites. For example, I got my from and also the bulb for a in my house is wearing out, so my dad is going to buy a bulb on It is things like this that make life that much easier for the because this way these people don't have to drive to the store to buy something, that is, if they can wait a week or two for the product to arrive. These are the kinds of things that make me feel that computers are beneficial to society. I know they might not be the best reasons, but they are quite important to me. Being able to type essays, play games and socialize, and order products form websites is just amazing. These are some of the reasons that I and others love computers. But I have a question for you, why do you like or dislike computers?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"final_score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 0,\n        \"max\": 10,\n        \"num_unique_values\": 11,\n        \"samples\": [\n          10,\n          6,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"clean_essay\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 12972,\n        \"samples\": [\n          \"The features setting affect cyclist many ways  He riding bike along road encounters dilema weeds crossed path ridiculously large snake  Blocked pavement front me He stop snake showed freaked  He problems thirst already deal snake really look like diamondback sees building ahead discovers its walrus Grape Juice factory  He thought might water realized abandoned  Relating thirst  left grabbed pebbles Id read sucking stones helps takes mind thirst allowing spit left circulate  came across fishing camp received instructions go  This affected got secure place got proper directions learn mistake listening older men beginning  The features\",\n          \"The author concludes story paragraph cold brufield author never wanted around cold sesion  At time realy cold\",\n          \"Computers  much talked subject  Did know homes least one computer  And goes Some people nt like true  hand people  I computer  much  example help writing  I play games socialize social networking sites  IM  s   even help order product form website like Like I said  I computer I use help write  At school english  I would use computer help writing prompt  I also use write conclusions science labs  There lot kids well  really helpful  That one reasons I think computers beneficial society  Another reason I think computers beneficial society play games  like  world warcraft     CAPS classics like   CAPS There millions people play games computer  Also socialize social networking sites  like twitter  also  IM   friends  IM  stands messaging  kind like email except instantaneous  friend conversation computer  Also video chatting  kind like phone except see person re talking computer  almost like person videochatting meeting face face   A third reason I feel computers beneficial society order product internet form shop websites  For example  I got also bulb house wearing  dad going buy bulb It things like make life much easier way people nt drive store buy something   wait week two product arrive  These kinds things make feel computers beneficial society  I know might best reasons  quite important  Being able type essays  play games socialize  order products form websites amazing  These reasons I others love computers  But I question  like dislike computers \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"char_count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 719,\n        \"min\": 7,\n        \"max\": 4817,\n        \"num_unique_values\": 2729,\n        \"samples\": [\n          779,\n          2927,\n          237\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"word_count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 173,\n        \"min\": 2,\n        \"max\": 1056,\n        \"num_unique_values\": 842,\n        \"samples\": [\n          727,\n          560,\n          572\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sent_count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 10,\n        \"min\": 1,\n        \"max\": 90,\n        \"num_unique_values\": 78,\n        \"samples\": [\n          9,\n          16,\n          31\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"avg_word_len\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.360651043035522,\n        \"min\": 2.9,\n        \"max\": 5.875,\n        \"num_unique_values\": 9181,\n        \"samples\": [\n          3.949074074074074,\n          4.255681818181818,\n          3.323529411764706\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"spell_err_count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7,\n        \"min\": 0,\n        \"max\": 71,\n        \"num_unique_values\": 63,\n        \"samples\": [\n          66,\n          60,\n          11\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"noun_count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 36,\n        \"min\": 0,\n        \"max\": 309,\n        \"num_unique_values\": 206,\n        \"samples\": [\n          69,\n          80,\n          188\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"adj_count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 37,\n        \"min\": 0,\n        \"max\": 263,\n        \"num_unique_values\": 211,\n        \"samples\": [\n          71,\n          161,\n          10\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"verb_count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 13,\n        \"min\": 0,\n        \"max\": 83,\n        \"num_unique_values\": 82,\n        \"samples\": [\n          12,\n          18,\n          46\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"adv_count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 13,\n        \"min\": 0,\n        \"max\": 99,\n        \"num_unique_values\": 91,\n        \"samples\": [\n          14,\n          21,\n          72\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Make Dataset\n",
        "y = df['domain1_score']\n",
        "df.drop('domain1_score',inplace=True,axis=1)\n",
        "X=df"
      ],
      "metadata": {
        "id": "v3EnjvLFNwlS"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
      ],
      "metadata": {
        "id": "8_Mt2AriN3ei"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h9EdEsxKN71M",
        "outputId": "970b9846-c4cd-4abf-b6ec-13778932ad69"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9083, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_e = X_train['essay'].tolist()\n",
        "test_e = X_test['essay'].tolist()"
      ],
      "metadata": {
        "id": "N0gGpi-6OAAL"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# Download the 'stopwords' dataset\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Download the 'punkt' dataset for sentence tokenization\n",
        "nltk.download('punkt')  # This line is added to download the missing resource\n",
        "\n",
        "train_sents=[]\n",
        "test_sents=[]\n",
        "\n",
        "# Now you can access the stopwords\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def sent2word(x):\n",
        "    x=re.sub(\"[^A-Za-z]\",\" \",x)\n",
        "    x.lower()\n",
        "    filtered_sentence = []\n",
        "    words=x.split()\n",
        "    for w in words:\n",
        "        if w not in stop_words:\n",
        "            filtered_sentence.append(w)\n",
        "    return filtered_sentence\n",
        "\n",
        "def essay2word(essay):\n",
        "    essay = essay.strip()\n",
        "    tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
        "    raw = tokenizer.tokenize(essay)\n",
        "    final_words=[]\n",
        "    for i in raw:\n",
        "        if(len(i)>0):\n",
        "            final_words.append(sent2word(i))\n",
        "    return final_words\n",
        "\n",
        "for i in train_e:\n",
        "    train_sents+=essay2word(i)\n",
        "\n",
        "for i in test_e:\n",
        "    test_sents+=essay2word(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xblzWXXPO6hK",
        "outputId": "aacc1bce-e4a5-4375-f9dd-73150b20df30"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_sents)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tf2djrr1PAWE",
        "outputId": "b50cfb2b-c498-420a-ffee-837aa5b6ba18"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "116500"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_sents[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PCgWH6dQPHpX",
        "outputId": "ac946e14-0f57-445d-cbcf-4bfb68ebe88d"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['It',\n",
              " 'first',\n",
              " 'day',\n",
              " 'high',\n",
              " 'school',\n",
              " 'gut',\n",
              " 'full',\n",
              " 'butterflies',\n",
              " 'make',\n",
              " 'want',\n",
              " 'run',\n",
              " 'bathrooms',\n",
              " 'hide',\n",
              " 'world']"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_model():\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(300, dropout=0.4, recurrent_dropout=0.4, input_shape=[1, 300], return_sequences=True))\n",
        "    model.add(LSTM(64, recurrent_dropout=0.4))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(1, activation='relu'))\n",
        "    model.compile(loss='mean_squared_error', optimizer='rmsprop', metrics=['mae'])\n",
        "    model.summary()\n",
        "    return model"
      ],
      "metadata": {
        "id": "lspjhcy7PLcR"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Training Word2Vec model\n",
        "num_features = 300\n",
        "min_word_count = 40\n",
        "num_workers = 4\n",
        "context = 10\n",
        "downsampling = 1e-3\n",
        "\n",
        "# Install gensim if you haven't already\n",
        "!pip install gensim\n",
        "\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "# Change 'size' to 'vector_size'\n",
        "model = Word2Vec(train_sents,\n",
        "                 workers=num_workers,\n",
        "                 vector_size=num_features,  # Changed 'size' to 'vector_size'\n",
        "                 min_count=min_word_count,\n",
        "                 window=context,\n",
        "                 sample=downsampling)\n",
        "\n",
        "model.init_sims(replace=True)\n",
        "model.wv.save_word2vec_format('word2vecmodel.bin', binary=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8-L6avMyPhYM",
        "outputId": "81ebcecc-5db0-4195-906a-bd6066ff0e6f"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (4.3.3)\n",
            "Requirement already satisfied: numpy<2.0,>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.26.4)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim) (7.0.5)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open>=1.8.1->gensim) (1.16.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-21-a8daf568ad59>:21: DeprecationWarning: Call to deprecated `init_sims` (Gensim 4.0.0 implemented internal optimizations that make calls to init_sims() unnecessary. init_sims() is now obsoleted and will be completely removed in future versions. See https://github.com/RaRe-Technologies/gensim/wiki/Migrating-from-Gensim-3.x-to-4).\n",
            "  model.init_sims(replace=True)\n",
            "WARNING:gensim.models.keyedvectors:destructive init_sims(replace=True) deprecated & no longer required for space-efficiency\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def makeVec(words, model, num_features):\n",
        "    vec = np.zeros((num_features,),dtype=\"float32\")\n",
        "    noOfWords = 0.\n",
        "    # Use index_to_key instead of index2word\n",
        "    index2word_set = set(model.wv.index_to_key)\n",
        "    for i in words:\n",
        "        if i in index2word_set:\n",
        "            noOfWords += 1\n",
        "            vec = np.add(vec,model.wv[i]) # Use model.wv[i] to access word vectors\n",
        "    vec = np.divide(vec,noOfWords)\n",
        "    return vec\n",
        "\n",
        "\n",
        "def getVecs(essays, model, num_features):\n",
        "    c=0\n",
        "    essay_vecs = np.zeros((len(essays),num_features),dtype=\"float32\")\n",
        "    for i in essays:\n",
        "        essay_vecs[c] = makeVec(i, model, num_features)\n",
        "        c+=1\n",
        "    return essay_vecs\n",
        "\n",
        "\n",
        "clean_train=[]\n",
        "for i in train_e:\n",
        "    clean_train.append(sent2word(i))\n",
        "training_vectors = getVecs(clean_train, model, num_features)\n",
        "\n",
        "clean_test=[]\n",
        "\n",
        "for i in test_e:\n",
        "    clean_test.append(sent2word(i))\n",
        "testing_vectors = getVecs(clean_test, model, num_features)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "53z4VqAOQd9h",
        "outputId": "31728de6-54d1-4f87-b1a3-a7b80eaad210"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-23-1562c0dd135e>:10: RuntimeWarning: invalid value encountered in divide\n",
            "  vec = np.divide(vec,noOfWords)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_vectors.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oH4AzHrHQjSV",
        "outputId": "a35c91ca-cf14-4152-9346-55ac86501799"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9083, 300)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_vectors = np.array(training_vectors)\n",
        "testing_vectors = np.array(testing_vectors)\n",
        "\n",
        "# Reshaping train and test vectors to 3 dimensions. (1 represnts one timestep)\n",
        "training_vectors = np.reshape(training_vectors, (training_vectors.shape[0], 1, training_vectors.shape[1]))\n",
        "testing_vectors = np.reshape(testing_vectors, (testing_vectors.shape[0], 1, testing_vectors.shape[1]))\n",
        "lstm_model = get_model()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "UzHSl8M_QocR",
        "outputId": "4acbf31e-c9d5-4b24-9ce0-258b7693137f"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m\n",
              "\n",
              " lstm (\u001b[38;5;33mLSTM\u001b[0m)                           (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m300\u001b[0m)                       \u001b[38;5;34m721,200\u001b[0m \n",
              "\n",
              " lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                         (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                            \u001b[38;5;34m93,440\u001b[0m \n",
              "\n",
              " dropout (\u001b[38;5;33mDropout\u001b[0m)                     (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                                 \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " dense (\u001b[38;5;33mDense\u001b[0m)                         (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                                 \u001b[38;5;34m65\u001b[0m \n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"font-weight: bold\"> Layer (type)                         </span><span style=\"font-weight: bold\"> Output Shape                </span><span style=\"font-weight: bold\">         Param # </span>\n",
              "\n",
              " lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                           (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)                       <span style=\"color: #00af00; text-decoration-color: #00af00\">721,200</span> \n",
              "\n",
              " lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                         (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                            <span style=\"color: #00af00; text-decoration-color: #00af00\">93,440</span> \n",
              "\n",
              " dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                         (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                                 <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> \n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m814,705\u001b[0m (3.11 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">814,705</span> (3.11 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m814,705\u001b[0m (3.11 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">814,705</span> (3.11 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_vectors.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vttfd8dTQtqD",
        "outputId": "4dc7f7d3-0030-454d-bb98-2c9db8c061a4"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9083, 1, 300)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lstm_model.fit(training_vectors, y_train, batch_size=64, epochs=150)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SSyc8EbCQw3o",
        "outputId": "aabaf235-ffd4-4c3d-c399-56766c51b52c"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "\u001b[1m142/142\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 20.7555 - mae: 3.7699\n",
            "Epoch 2/150\n",
            "\u001b[1m142/142\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - loss: 5.6753 - mae: 1.8955\n",
            "Epoch 3/150\n",
            "\u001b[1m142/142\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 33ms/step - loss: 5.3489 - mae: 1.8338\n",
            "Epoch 4/150\n",
            "\u001b[1m142/142\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 30ms/step - loss: 5.1996 - mae: 1.8061\n",
            "Epoch 5/150\n",
            "\u001b[1m142/142\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 5.1515 - mae: 1.7969\n",
            "Epoch 6/150\n",
            "\u001b[1m142/142\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - loss: 5.2462 - mae: 1.8157\n",
            "Epoch 7/150\n",
            "\u001b[1m142/142\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 28ms/step - loss: 5.1379 - mae: 1.7873\n",
            "Epoch 8/150\n",
            "\u001b[1m142/142\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - loss: 5.1026 - mae: 1.7936\n",
            "Epoch 9/150\n",
            "\u001b[1m142/142\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - loss: 5.1259 - mae: 1.7807\n",
            "Epoch 10/150\n",
            "\u001b[1m142/142\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 5.1408 - mae: 1.7826\n",
            "Epoch 11/150\n",
            "\u001b[1m142/142\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 23ms/step - loss: 4.9967 - mae: 1.7565\n",
            "Epoch 12/150\n",
            "\u001b[1m142/142\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - loss: 4.9696 - mae: 1.7557\n",
            "Epoch 13/150\n",
            "\u001b[1m142/142\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 5.0346 - mae: 1.7669\n",
            "Epoch 14/150\n",
            "\u001b[1m142/142\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - loss: 4.8345 - mae: 1.7276\n",
            "Epoch 15/150\n",
            "\u001b[1m142/142\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - loss: 4.8856 - mae: 1.7556\n",
            "Epoch 16/150\n",
            "\u001b[1m142/142\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 30ms/step - loss: 4.8884 - mae: 1.7344\n",
            "Epoch 17/150\n",
            "\u001b[1m142/142\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - loss: 4.9447 - mae: 1.7418\n",
            "Epoch 18/150\n",
            "\u001b[1m142/142\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 4.8775 - mae: 1.7314\n",
            "Epoch 19/150\n",
            "\u001b[1m142/142\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - loss: 4.8362 - mae: 1.7307\n",
            "Epoch 20/150\n",
            "\u001b[1m142/142\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 4.8323 - mae: 1.7329\n",
            "Epoch 21/150\n",
            "\u001b[1m142/142\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - loss: 4.8426 - mae: 1.7244\n",
            "Epoch 22/150\n",
            "\u001b[1m142/142\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - loss: 4.7509 - mae: 1.7147\n",
            "Epoch 23/150\n",
            "\u001b[1m142/142\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 4.7600 - mae: 1.7102\n",
            "Epoch 24/150\n",
            "\u001b[1m142/142\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 26ms/step - loss: 4.8708 - mae: 1.7428\n",
            "Epoch 25/150\n",
            "\u001b[1m142/142\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - loss: 4.6948 - mae: 1.6969\n",
            "Epoch 26/150\n",
            "\u001b[1m142/142\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 4.8443 - mae: 1.7331\n",
            "Epoch 27/150\n",
            "\u001b[1m142/142\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - loss: 4.6746 - mae: 1.6978\n",
            "Epoch 28/150\n",
            "\u001b[1m142/142\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 4.6791 - mae: 1.7018\n",
            "Epoch 29/150\n",
            "\u001b[1m142/142\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - loss: 4.6381 - mae: 1.6944\n",
            "Epoch 30/150\n",
            "\u001b[1m142/142\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 4.6346 - mae: 1.6930\n",
            "Epoch 31/150\n",
            "\u001b[1m142/142\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - loss: 4.5641 - mae: 1.6690\n",
            "Epoch 32/150\n",
            "\u001b[1m142/142\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 28ms/step - loss: 4.5958 - mae: 1.6754\n",
            "Epoch 33/150\n",
            "\u001b[1m142/142\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 4.7002 - mae: 1.6842\n",
            "Epoch 34/150\n",
            "\u001b[1m142/142\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 4.5961 - mae: 1.6670\n",
            "Epoch 35/150\n",
            "\u001b[1m142/142\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 4.3755 - mae: 1.6391\n",
            "Epoch 36/150\n",
            "\u001b[1m142/142\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - loss: 4.4906 - mae: 1.6505\n",
            "Epoch 37/150\n",
            "\u001b[1m142/142\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - loss: 4.2479 - mae: 1.6093\n",
            "Epoch 38/150\n",
            "\u001b[1m142/142\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - loss: 4.3453 - mae: 1.6302\n",
            "Epoch 39/150\n",
            "\u001b[1m142/142\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 17ms/step - loss: 4.4410 - mae: 1.6409\n",
            "Epoch 40/150\n",
            "\u001b[1m142/142\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 4.4343 - mae: 1.6523\n",
            "Epoch 41/150\n",
            "\u001b[1m142/142\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 4.3052 - mae: 1.6115\n",
            "Epoch 42/150\n",
            "\u001b[1m142/142\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 27ms/step - loss: 4.3182 - mae: 1.6195\n",
            "Epoch 43/150\n",
            "\u001b[1m142/142\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 4.3725 - mae: 1.6239\n",
            "Epoch 44/150\n",
            "\u001b[1m142/142\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 4.3926 - mae: 1.6274\n",
            "Epoch 45/150\n",
            "\u001b[1m142/142\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 4.2235 - mae: 1.6069\n",
            "Epoch 46/150\n",
            "\u001b[1m142/142\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 4.2228 - mae: 1.6009\n",
            "Epoch 47/150\n",
            "\u001b[1m142/142\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 4.2397 - mae: 1.6055\n",
            "Epoch 48/150\n",
            "\u001b[1m142/142\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 17ms/step - loss: 4.2555 - mae: 1.6184\n",
            "Epoch 49/150\n",
            "\u001b[1m142/142\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 4.1848 - mae: 1.6020\n",
            "Epoch 50/150\n",
            "\u001b[1m142/142\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 4.2944 - mae: 1.6240\n",
            "Epoch 51/150\n",
            "\u001b[1m142/142\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 4.3637 - mae: 1.6336\n",
            "Epoch 52/150\n",
            "\u001b[1m142/142\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - loss: 4.2691 - mae: 1.6111\n",
            "Epoch 53/150\n",
            "\u001b[1m142/142\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 4.2252 - mae: 1.6061\n",
            "Epoch 54/150\n",
            "\u001b[1m142/142\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 4.1764 - mae: 1.5891\n",
            "Epoch 55/150\n",
            "\u001b[1m142/142\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 4.1189 - mae: 1.5878\n",
            "Epoch 56/150\n",
            "\u001b[1m142/142\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 27ms/step - loss: 4.0952 - mae: 1.5841\n",
            "Epoch 57/150\n",
            "\u001b[1m142/142\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 26ms/step - loss: 4.1074 - mae: 1.5850\n",
            "Epoch 58/150\n",
            "\u001b[1m142/142\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 4.0685 - mae: 1.5669\n",
            "Epoch 59/150\n",
            "\u001b[1m142/142\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - loss: 4.1794 - mae: 1.6031\n",
            "Epoch 60/150\n",
            "\u001b[1m142/142\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - loss: 4.0272 - mae: 1.5758\n",
            "Epoch 61/150\n",
            "\u001b[1m142/142\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - loss: 4.0131 - mae: 1.5545\n",
            "Epoch 62/150\n",
            "\u001b[1m142/142\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 4.0593 - mae: 1.5692\n",
            "Epoch 63/150\n",
            "\u001b[1m142/142\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 28ms/step - loss: 3.9822 - mae: 1.5691\n",
            "Epoch 64/150\n",
            "\u001b[1m142/142\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - loss: 4.0210 - mae: 1.5667\n",
            "Epoch 65/150\n",
            "\u001b[1m142/142\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 4.0033 - mae: 1.5552\n",
            "Epoch 66/150\n",
            "\u001b[1m142/142\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 3.9544 - mae: 1.5537\n",
            "Epoch 67/150\n",
            "\u001b[1m142/142\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 3.9436 - mae: 1.5472\n",
            "Epoch 68/150\n",
            "\u001b[1m142/142\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 32ms/step - loss: 4.0271 - mae: 1.5590\n",
            "Epoch 69/150\n",
            "\u001b[1m142/142\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 3.8711 - mae: 1.5357\n",
            "Epoch 70/150\n",
            "\u001b[1m142/142\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 3.8506 - mae: 1.5298\n",
            "Epoch 71/150\n",
            "\u001b[1m142/142\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - loss: 3.8216 - mae: 1.5232\n",
            "Epoch 72/150\n",
            "\u001b[1m142/142\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 3.8326 - mae: 1.5323\n",
            "Epoch 73/150\n",
            "\u001b[1m142/142\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - loss: 3.8357 - mae: 1.5316\n",
            "Epoch 74/150\n",
            "\u001b[1m142/142\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 3.8148 - mae: 1.5246\n",
            "Epoch 75/150\n",
            "\u001b[1m142/142\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 3.7748 - mae: 1.5122\n",
            "Epoch 76/150\n",
            "\u001b[1m142/142\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 3.8242 - mae: 1.5191\n",
            "Epoch 77/150\n",
            "\u001b[1m142/142\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 37ms/step - loss: 3.8171 - mae: 1.5259\n",
            "Epoch 78/150\n",
            "\u001b[1m142/142\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 33ms/step - loss: 3.8584 - mae: 1.5358\n",
            "Epoch 79/150\n",
            "\u001b[1m142/142\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 3.7764 - mae: 1.5127\n",
            "Epoch 80/150\n",
            "\u001b[1m142/142\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 3.8040 - mae: 1.5209\n",
            "Epoch 81/150\n",
            "\u001b[1m142/142\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 3.7929 - mae: 1.5237\n",
            "Epoch 82/150\n",
            "\u001b[1m142/142\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 29ms/step - loss: 3.7728 - mae: 1.5112\n",
            "Epoch 83/150\n",
            "\u001b[1m142/142\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - loss: 3.6703 - mae: 1.4916\n",
            "Epoch 84/150\n",
            "\u001b[1m142/142\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 3.6873 - mae: 1.4996\n",
            "Epoch 85/150\n",
            "\u001b[1m142/142\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 3.7627 - mae: 1.5051\n",
            "Epoch 86/150\n",
            "\u001b[1m142/142\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 28ms/step - loss: 3.6668 - mae: 1.4892\n",
            "Epoch 87/150\n",
            "\u001b[1m142/142\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - loss: 3.6208 - mae: 1.4770\n",
            "Epoch 88/150\n",
            "\u001b[1m142/142\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - loss: 3.7402 - mae: 1.5065\n",
            "Epoch 89/150\n",
            "\u001b[1m142/142\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 3.7600 - mae: 1.5181\n",
            "Epoch 90/150\n",
            "\u001b[1m142/142\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 3.6555 - mae: 1.4920\n",
            "Epoch 91/150\n",
            "\u001b[1m142/142\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 29ms/step - loss: 3.6773 - mae: 1.4944\n",
            "Epoch 92/150\n",
            "\u001b[1m142/142\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 3.6703 - mae: 1.4888\n",
            "Epoch 93/150\n",
            "\u001b[1m142/142\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - loss: 3.6783 - mae: 1.4918\n",
            "Epoch 94/150\n",
            "\u001b[1m142/142\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 3.6480 - mae: 1.4800\n",
            "Epoch 95/150\n",
            "\u001b[1m142/142\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 26ms/step - loss: 3.6510 - mae: 1.4881\n",
            "Epoch 96/150\n",
            "\u001b[1m142/142\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 17ms/step - loss: 3.5012 - mae: 1.4505\n",
            "Epoch 97/150\n",
            "\u001b[1m142/142\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 3.5847 - mae: 1.4750\n",
            "Epoch 98/150\n",
            "\u001b[1m142/142\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 3.5582 - mae: 1.4670\n",
            "Epoch 99/150\n",
            "\u001b[1m142/142\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 3.5558 - mae: 1.4709\n",
            "Epoch 100/150\n",
            "\u001b[1m142/142\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 29ms/step - loss: 3.5949 - mae: 1.4668\n",
            "Epoch 101/150\n",
            "\u001b[1m142/142\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 3.6363 - mae: 1.4905\n",
            "Epoch 102/150\n",
            "\u001b[1m142/142\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 3.4237 - mae: 1.4420\n",
            "Epoch 103/150\n",
            "\u001b[1m142/142\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 3.4996 - mae: 1.4678\n",
            "Epoch 104/150\n",
            "\u001b[1m142/142\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 3.4940 - mae: 1.4576\n",
            "Epoch 105/150\n",
            "\u001b[1m142/142\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 27ms/step - loss: 3.4939 - mae: 1.4553\n",
            "Epoch 106/150\n",
            "\u001b[1m142/142\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 17ms/step - loss: 3.4723 - mae: 1.4520\n",
            "Epoch 107/150\n",
            "\u001b[1m142/142\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 3.6038 - mae: 1.4772\n",
            "Epoch 108/150\n",
            "\u001b[1m142/142\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 3.4905 - mae: 1.4582\n",
            "Epoch 109/150\n",
            "\u001b[1m142/142\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - loss: 3.4732 - mae: 1.4568\n",
            "Epoch 110/150\n",
            "\u001b[1m142/142\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 28ms/step - loss: 3.5490 - mae: 1.4728\n",
            "Epoch 111/150\n",
            "\u001b[1m142/142\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 3.5490 - mae: 1.4535\n",
            "Epoch 112/150\n",
            "\u001b[1m142/142\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 3.5851 - mae: 1.4775\n",
            "Epoch 113/150\n",
            "\u001b[1m142/142\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - loss: 3.4310 - mae: 1.4265\n",
            "Epoch 114/150\n",
            "\u001b[1m142/142\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 3.5434 - mae: 1.4732\n",
            "Epoch 115/150\n",
            "\u001b[1m142/142\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 3.3428 - mae: 1.4268\n",
            "Epoch 116/150\n",
            "\u001b[1m142/142\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - loss: 3.4098 - mae: 1.4354\n",
            "Epoch 117/150\n",
            "\u001b[1m142/142\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - loss: 3.5105 - mae: 1.4601\n",
            "Epoch 118/150\n",
            "\u001b[1m142/142\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 3.5660 - mae: 1.4683\n",
            "Epoch 119/150\n",
            "\u001b[1m142/142\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - loss: 3.4246 - mae: 1.4298\n",
            "Epoch 120/150\n",
            "\u001b[1m142/142\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 28ms/step - loss: 3.4905 - mae: 1.4652\n",
            "Epoch 121/150\n",
            "\u001b[1m142/142\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 3.4223 - mae: 1.4366\n",
            "Epoch 122/150\n",
            "\u001b[1m142/142\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 3.4496 - mae: 1.4363\n",
            "Epoch 123/150\n",
            "\u001b[1m142/142\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 3.4005 - mae: 1.4338\n",
            "Epoch 124/150\n",
            "\u001b[1m142/142\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 25ms/step - loss: 3.4222 - mae: 1.4369\n",
            "Epoch 125/150\n",
            "\u001b[1m142/142\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 27ms/step - loss: 3.3966 - mae: 1.4315\n",
            "Epoch 126/150\n",
            "\u001b[1m142/142\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - loss: 3.4344 - mae: 1.4465\n",
            "Epoch 127/150\n",
            "\u001b[1m142/142\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - loss: 3.4442 - mae: 1.4491\n",
            "Epoch 128/150\n",
            "\u001b[1m142/142\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 25ms/step - loss: 3.5121 - mae: 1.4473\n",
            "Epoch 129/150\n",
            "\u001b[1m142/142\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 3.4706 - mae: 1.4495\n",
            "Epoch 130/150\n",
            "\u001b[1m142/142\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - loss: 3.3897 - mae: 1.4259\n",
            "Epoch 131/150\n",
            "\u001b[1m142/142\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 3.4162 - mae: 1.4422\n",
            "Epoch 132/150\n",
            "\u001b[1m142/142\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 29ms/step - loss: 3.3238 - mae: 1.4135\n",
            "Epoch 133/150\n",
            "\u001b[1m142/142\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 3.3641 - mae: 1.4234\n",
            "Epoch 134/150\n",
            "\u001b[1m142/142\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 3.3996 - mae: 1.4340\n",
            "Epoch 135/150\n",
            "\u001b[1m142/142\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 3.3762 - mae: 1.4308\n",
            "Epoch 136/150\n",
            "\u001b[1m142/142\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 3.3496 - mae: 1.4251\n",
            "Epoch 137/150\n",
            "\u001b[1m142/142\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - loss: 3.4099 - mae: 1.4357\n",
            "Epoch 138/150\n",
            "\u001b[1m142/142\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 29ms/step - loss: 3.3788 - mae: 1.4146\n",
            "Epoch 139/150\n",
            "\u001b[1m142/142\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 3.3854 - mae: 1.4260\n",
            "Epoch 140/150\n",
            "\u001b[1m142/142\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - loss: 3.3490 - mae: 1.4163\n",
            "Epoch 141/150\n",
            "\u001b[1m142/142\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 17ms/step - loss: 3.2831 - mae: 1.4059\n",
            "Epoch 142/150\n",
            "\u001b[1m142/142\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - loss: 3.3174 - mae: 1.4157\n",
            "Epoch 143/150\n",
            "\u001b[1m142/142\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 3.4453 - mae: 1.4493\n",
            "Epoch 144/150\n",
            "\u001b[1m142/142\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - loss: 3.3294 - mae: 1.4244\n",
            "Epoch 145/150\n",
            "\u001b[1m142/142\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 3.4419 - mae: 1.4427\n",
            "Epoch 146/150\n",
            "\u001b[1m142/142\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 3.2981 - mae: 1.4077\n",
            "Epoch 147/150\n",
            "\u001b[1m142/142\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 3.3362 - mae: 1.4154\n",
            "Epoch 148/150\n",
            "\u001b[1m142/142\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 27ms/step - loss: 3.2679 - mae: 1.3994\n",
            "Epoch 149/150\n",
            "\u001b[1m142/142\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 26ms/step - loss: 3.3248 - mae: 1.4193\n",
            "Epoch 150/150\n",
            "\u001b[1m142/142\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 3.3116 - mae: 1.4176\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x79a466c2d9c0>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lstm_model.save('final_lstm.h5')\n",
        "y_pred = lstm_model.predict(testing_vectors)\n",
        "y_pred = np.around(y_pred)\n",
        "y_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dpqlGl4AS-1l",
        "outputId": "359fdecf-a0bf-4a65-df17-67be8e1aabee"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m122/122\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[3.],\n",
              "       [5.],\n",
              "       [6.],\n",
              "       ...,\n",
              "       [7.],\n",
              "       [7.],\n",
              "       [9.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    }
  ]
}